splits:
  train: 0.8
  val: 0.2
  test: 0.0

split_cols_in_dataset:
  train: 'train'
  val: 'val'
  test: 'test'

tokenize_data:
  args:
    max_length: 2048
    use_sep: False