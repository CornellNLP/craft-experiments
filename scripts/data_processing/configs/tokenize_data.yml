splits:
  train: 0.8
  val: 0.2
  test: 0.0

split_cols_in_dataset:
  train: 'train'
  val: 'val'
  test: 'test'

tokenize_data:
  args:
    train_val:
      max_length: 2048
      use_cls: False
      label_at_each_utt: False
    val_test:
      max_length: 2048
      use_cls: False
      label_at_each_utt: True
