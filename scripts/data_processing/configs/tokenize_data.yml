splits:
  train: 0.8
  val: 0.2
  test: 0.0

split_cols_in_dataset:
  train: 'train'
  val: 'val'
  test: 'test'

tokenize_data:
  args:
    finetune:
      train_val:
        max_length: 2048
        use_cls: False
        label_at_each_utt: False
        label_as_lm: False
      val_test:
        max_length: 2048
        use_cls: False
        label_at_each_utt: True
        label_as_lm: False
    finetune_as_lm:
      train_val:
        max_length: 2048
        use_cls: False
        label_at_each_utt: False
        label_as_lm: True
      val_test:
        max_length: null
        use_cls: False
        label_at_each_utt: False
        label_as_lm: True
