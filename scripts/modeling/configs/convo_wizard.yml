general:
  device: 'cuda:1'

tokenizer:
  id: 'convo-uncased'
  use_cls: False

transformer:
  id: 'convo_wizard'
  args:
    embedding_dim: 300
    hidden_dim: 512
    max_relative_position: null
    use_sinusoidal_init: True
    positional_network_type: 'ffnn'
    output_dim: 2
    use_explicit_lm_head: False
    classifier_head_type: 'rnn'
    num_heads: 6
    causal: True
    num_encoder_layers: 4
    max_length: 2048
    pad_token_position: 0
    pad_tok_type: 0
    num_token_types: 2
    attention_dropout: 0.05
    dropout: 0.1
  finetuning_overrides: # https://arxiv.org/pdf/2305.13230.pdf
    attention_dropout: 0.1
    dropout: 0.1

optimizer:
  id: 'noam'
  adam:
    args:
      lr: 2.0e-3
      betas: [ 0.9, 0.999 ]
      eps: 1.0e-9
  adamw:
    args:
      lr: 2.0e-5
      betas: [ 0.9, 0.98 ]
      weight_decay: 0.01
  args:
    num_warmup_steps: 4000

trainer:
  id: 'convo_wizard_trainer'
  args:
    generator:
      use_relative_position_ids: False
      is_labeled_data: False
      freeze_non_cls_layers: False
      labels_ignore_idx: 0
      use_class_weights: False
      gradient_clip_value: 0.75
      num_workers: 4
      use_mixed_precision: True
    discriminator:
      use_relative_position_ids: False
      is_labeled_data: True
      freeze_non_cls_layers: True
      labels_ignore_idx: -100
      use_class_weights: True
      gradient_clip_value: 0.75
      num_workers: 4
      use_mixed_precision: True

train_and_eval:
  args:
    generator: # 180 epochs: 120 epochs (cmv-small), rest randomly sampled per 20 epochs (cmv-full)
      batch_size: 14
      num_steps_per_epoch: 100000
      num_epochs: 20
      checkpoint_every: 1
    weak_supervision: # 12 epochs: random sampling per 3 epochs with interleaved annealing
      batch_size: 14
      num_steps_per_epoch: 40002
      num_epochs: 3
      checkpoint_every: 1
    discriminator:
      batch_size: 14
      num_steps_per_epoch: null
      num_epochs: 3
      checkpoint_every: 1
  finetune_pretrain_interleave: # annealing: [0.4, 0.6], [0.5, 0.5], [0.6, 0.4], [0.7, 0.3]
    args:
      probabilities: [ 0.7, 0.3 ]
      stopping_strategy: 'first_exhausted'

test:
  find_forecast_threshold_by: 'acc'
  args:
    batch_size: 14
    labels_ignore_idx: -100
    use_relative_position_ids: False
    use_mixed_precision: True
    num_workers: 4

test_as_lm:
  find_forecast_threshold_by: 'acc'
  args:
    temperature: 1.0
    use_mixed_precision: True
    num_workers: 4

generate:
  args:
    max_new_tokens: 100
    temperature: 1.0
    num_samples: 10
    top_k: 50
